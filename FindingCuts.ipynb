{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph $(V, E)$ with nodes $v\\subset\\mathbb{N}$ as subsets of integers\n",
    "Strategy for merging:\n",
    "1. Draw a set of edges $F\\subseteq E$ somehow\n",
    "2. Identify connected components $\\mathcal{C}=\\{C_1,\\dotsc, C_k\\}$ of $(V, F)$. They form the new set of nodes\n",
    "3. Compute new adjacency matrix $A^\\prime$ by summing entries of $A$ blockwise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule of thumb for choosing temperature $\\tau$:\n",
    "If there are $m$ edges in an unweighted graph, the amount of chosen edges is distrubted as Bin($e$, $n^{-\\tau}$). Therefore, the expected number of chosen edges is $n^{1-\\tau}$, and a choice of \n",
    "$$\n",
    "\\tau=\\frac{\\log(2)}{\\log(m)}\n",
    "$$\n",
    "leads to $m/2$ in expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindCuts(object):\n",
    "    def __init__(self, A, sample_fn, partition_fn, quality_fn):\n",
    "        self.A = A\n",
    "        self.V = [{i} for i in range(nx.number_of_nodes(G))]\n",
    "        self.sample_fn = sample_fn\n",
    "        self.partition_fn = partition_fn\n",
    "        self.quality_fn = quality_fn\n",
    "    \n",
    "    def _merge_nodes(self, V, component):\n",
    "        \"\"\" Merge the sets of V that are indexed in component.\"\"\"\n",
    "        merged_node = set({})\n",
    "        for idx in component:\n",
    "            merged_node = merged_node.union(V[idx])\n",
    "        return merged_node\n",
    "    \n",
    "    def _merge_edges(self, V, A, A_sampled):\n",
    "        \"\"\" Merge edges in A_sampled to obtain a new graph.\"\"\"\n",
    "        G_sampled = nx.from_numpy_array(A_sampled)\n",
    "        connected_components = list(nx.connected_components(G_sampled))\n",
    "        V_coarse = [self._merge_nodes(V, component) for component in connected_components]\n",
    "        n_coarse = len(V_coarse)\n",
    "        A_coarse = np.zeros((n_coarse, n_coarse))\n",
    "        for i in range(n_coarse):\n",
    "            for j in range(i+1, n_coarse):\n",
    "                for v in connected_components[i]:\n",
    "                    for w in connected_components[j]:\n",
    "                        A_coarse[i, j] += A[v, w] \n",
    "        A_coarse += A_coarse.T\n",
    "        return V_coarse, A_coarse\n",
    "        \n",
    "    def get_cuts(self, T):\n",
    "        \"\"\" T: number of partitions\"\"\"\n",
    "        V = self.V\n",
    "        A = self.A\n",
    "        for t in range(T):\n",
    "            A_sampled = self.sample_fn(A)\n",
    "            V, A = self._merge_edges(V, A, A_sampled)\n",
    "            if len(V)==1:\n",
    "                return\n",
    "            P = self.partition_fn(V, A, n=self.A.shape[0])\n",
    "            print(self.quality_fn(P), wcut(self.A, np.ones(self.A.shape[0]), P))\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted ratio cut with weighted kernelized k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input:__ Adjacency matrix $A$ with weighted edges, $w$ vector of node weights. <br>\n",
    "__Output:__ Cluster indicator vector x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted ratio cut (Wcut) is given by\n",
    "$$\n",
    "Wcut(A,A^c) = \\left(\\frac{1}{w(A)}+\\frac{1}{w(A^c)}\\right)cut(A,A^c)\\,,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "w(A) = \\sum_{i\\in A}w(i)\\quad\\text{and}\\quad cut(A,A^c)=\\sum_{i\\in A, j\\in A^c}w(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_edges(A, temperature=.7):\n",
    "    \"\"\" Sample each edge with a probability, scaled by the temperature.\n",
    "    Returns new edges in form of adjacency matrix\"\"\"\n",
    "    edges_idx = np.triu_indices_from(A, k=1)\n",
    "    edge_probs = (A[edges_idx] / A[edges_idx].sum())**temperature\n",
    "    sampled_edges = np.random.binomial(n=1, p=edge_probs)\n",
    "    is_sampled = (sampled_edges == 1)\n",
    "    sampled_edges_idx = (edges_idx[0][is_sampled], edges_idx[1][is_sampled])\n",
    "    A_sampled = np.zeros_like(A)\n",
    "    A_sampled[sampled_edges_idx] = 1\n",
    "    A_sampled += A_sampled.T\n",
    "    return A_sampled\n",
    "\n",
    "def wcut(A, w, x):\n",
    "    \"\"\" Computes weighted ratio cut value for a given flat vector x.\"\"\"\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    return (1 / (x @ w) + 1 / ((1 - x) @ w)) * (x @ A) @ (1 - x)\n",
    "\n",
    "def compute_wcut(A, w, sigma=0, t_max=100):\n",
    "    \"\"\" Compute weighted ratio cut with weighted kernel 2-means.\"\"\"\n",
    "    # Compute appropriate kernel matrix\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    \n",
    "    L = np.diag(np.sum(A, axis=1)) - A\n",
    "    K = np.diag(1 / w) * sigma + (np.diag(1 / w) @ (np.diag(w) - L)) @ np.diag(1 / w)\n",
    "    \n",
    "    # Perform weighted kernelized k-means with random initialization\n",
    "    n = A.shape[0]\n",
    "    x_old = np.random.binomial(n=1, p=.5, size=n)\n",
    "    x_old[0] = 1 - x_old[-1] # Hacky way to avoid having a vector of all 0 or all 1\n",
    "    D = np.zeros((n, 2))\n",
    "    for t in range(t_max):\n",
    "        for b in [0, 1]:\n",
    "            w_b = w * (x_old==b)\n",
    "            w_b_sum = w_b.sum()\n",
    "            D[:, b] = -2 * (K @ w_b) / w_b_sum + np.sum(w_b.reshape(-1, 1) * K * w_b) / w_b_sum ** 2\n",
    "        x_new = np.argmin(D, axis=1)        \n",
    "        if (x_old==x_new).all():\n",
    "            break\n",
    "        x_old = x_new\n",
    "    return x_new\n",
    "\n",
    "def compute_best_wcut(A, w=None, sigmas=np.linspace(-2, 2, 20)):\n",
    "    \"\"\" Compute weighted ratio cut for several sigma and take best.\"\"\"\n",
    "    x_best = []\n",
    "    best_val = np.inf\n",
    "    for sigma in sigmas:\n",
    "        x = compute_wcut(A, w, sigma=sigma)\n",
    "        if wcut(A, w, x) < best_val:\n",
    "            x_best = x\n",
    "            best_val = wcut(A, w, x)\n",
    "    return x_best\n",
    "\n",
    "def partition(V, A, n):\n",
    "    \"\"\" Compute coarse partition and translate to partition of original graph.\"\"\"\n",
    "    x_coarse = compute_best_wcut(A=A, w=np.array([len(v) for v in V]))\n",
    "    x = np.zeros(n)\n",
    "    for i,v in enumerate(V):\n",
    "        x[list(v)]= x_coarse[i]\n",
    "    return x\n",
    "\n",
    "def evaluate_partition_quality(x, sizes):\n",
    "    \"\"\" Evaluate the fractions that are separated by a partition in an SBM.\"\"\"\n",
    "    fractions = []\n",
    "    pos = 0\n",
    "    for i in range(len(sizes)):\n",
    "        fractions.append(x[pos: pos + sizes[i]].mean())\n",
    "        pos += sizes[i]\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Stochastical Block model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.array([50, 50])\n",
    "G = nx.stochastic_block_model(sizes=sizes, p=[[.8, .1],\n",
    "                                                 [.1, .8]])\n",
    "A = nx.to_numpy_array(G)\n",
    "V = [{i} for i in range(A.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54, 0.42]\n",
      "[0.6, 0.38]\n",
      "[0.42, 0.6]\n",
      "[0.44, 0.52]\n",
      "[0.58, 0.42]\n",
      "[0.6, 0.64]\n",
      "[0.5, 0.5]\n",
      "[0.42, 0.5]\n",
      "[0.4, 0.5]\n",
      "[0.46, 0.54]\n",
      "45.26410419712602\n"
     ]
    }
   ],
   "source": [
    "rnd_cuts = []\n",
    "for _ in range(10):\n",
    "    P = np.random.binomial(n=1, p=.5, size=A.shape[0])\n",
    "    print(evaluate_partition_quality(P, sizes=sizes))\n",
    "    rnd_cuts.append(wcut(A, None, P))\n",
    "mean = np.array(rnd_cuts).mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_blocks = np.zeros(A.shape[0])\n",
    "x_blocks[:sizes[0]] = 1\n",
    "wcut(A, np.ones(A.shape[0]), x_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36, 0.56] 44.32367149758454\n",
      "[0.62, 0.42] 43.7099358974359\n",
      "[0.58, 0.2] 41.488020176544765\n",
      "[0.68, 0.52] 43.87500000000001\n",
      "[0.34, 0.56] 43.43434343434343\n",
      "[0.24, 0.66] 39.03030303030303\n",
      "[0.42, 0.66] 43.51851851851852\n",
      "[0.92, 0.64] 41.31701631701632\n",
      "[0.86, 0.58] 42.65873015873016\n",
      "[0.14, 0.4] 42.719431760527655\n",
      "[0.98, 0.7] 41.07142857142857\n",
      "[0.98, 0.68] 40.25513819985825\n",
      "[0.92, 0.98] 44.21052631578947\n",
      "[0.96, 0.98] 42.611683848797256\n",
      "[0.02, 0.02] 42.3469387755102\n",
      "[0.02, 0.06] 43.489583333333336\n",
      "[0.98, 0.98] 43.87755102040816\n",
      "[0.02, 0.04] 43.6426116838488\n",
      "[0.02, 0.02] 43.87755102040816\n",
      "[0.98, 0.98] 43.87755102040816\n"
     ]
    }
   ],
   "source": [
    "findCuts = FindCuts(A=A, sample_fn=sample_edges, partition_fn=partition, \n",
    "                    quality_fn=lambda x: evaluate_partition_quality(x, sizes=sizes))\n",
    "findCuts.get_cuts(T=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.938311688311686"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcut(A=A, w=None, x=compute_best_wcut(A, sigmas=np.linspace(-10,10,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yu and Shi Postprocessing: spectral approach to Wcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
