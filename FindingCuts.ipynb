{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph $(V, E)$ with nodes $v\\subset\\mathbb{N}$ as subsets of integers\n",
    "Strategy for merging:\n",
    "1. Draw a set of edges $F\\subseteq E$ somehow\n",
    "2. Identify connected components $\\mathcal{C}=\\{C_1,\\dotsc, C_k\\}$ of $(V, F)$. They form the new set of nodes\n",
    "3. Compute new adjacency matrix $A^\\prime$ by summing entries of $A$ blockwise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule of thumb for choosing temperature $\\tau$:\n",
    "If there are $m$ edges in an unweighted graph, the amount of chosen edges is distrubted as Bin($e$, $n^{-\\tau}$). Therefore, the expected number of chosen edges is $n^{1-\\tau}$, and a choice of \n",
    "$$\n",
    "\\tau=\\frac{\\log(2)}{\\log(m)}\n",
    "$$\n",
    "leads to $m/2$ in expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindCuts(object):\n",
    "    def __init__(self, A, sample_fn, partition_fn, quality_fn):\n",
    "        self.A = A\n",
    "        self.V = [{i} for i in range(nx.number_of_nodes(G))]\n",
    "        self.sample_fn = sample_fn\n",
    "        self.partition_fn = partition_fn\n",
    "        self.quality_fn = quality_fn\n",
    "    \n",
    "    def _merge_nodes(self, V, component):\n",
    "        \"\"\" Merge the sets of V that are indexed in component.\"\"\"\n",
    "        merged_node = set({})\n",
    "        for idx in component:\n",
    "            merged_node = merged_node.union(V[idx])\n",
    "        return merged_node\n",
    "    \n",
    "    def _merge_edges(self, V, A, A_sampled):\n",
    "        \"\"\" Merge edges in A_sampled to obtain a new graph.\"\"\"\n",
    "        G_sampled = nx.from_numpy_array(A_sampled)\n",
    "        connected_components = list(nx.connected_components(G_sampled))\n",
    "        V_coarse = [self._merge_nodes(V, component) for component in connected_components]\n",
    "        n_coarse = len(V_coarse)\n",
    "        A_coarse = np.zeros((n_coarse, n_coarse))\n",
    "        for i in range(n_coarse):\n",
    "            for j in range(i+1, n_coarse):\n",
    "                for v in connected_components[i]:\n",
    "                    for w in connected_components[j]:\n",
    "                        A_coarse[i, j] += A[v, w] \n",
    "        A_coarse += A_coarse.T\n",
    "        return V_coarse, A_coarse\n",
    "        \n",
    "    def get_cuts(self, T):\n",
    "        \"\"\" T: number of partitions\"\"\"\n",
    "        V = self.V\n",
    "        A = self.A\n",
    "        for t in range(T):\n",
    "            A_sampled = self.sample_fn(A)\n",
    "            V, A = self._merge_edges(V, A, A_sampled)\n",
    "            if len(V)==1:\n",
    "                return\n",
    "            P = self.partition_fn(V, A, n=self.A.shape[0])\n",
    "            print(len(V), self.quality_fn(P), wcut(self.A, np.ones(self.A.shape[0]), P))\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted ratio cut with weighted kernelized k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input:__ Adjacency matrix $A$ with weighted edges, $w$ vector of node weights. <br>\n",
    "__Output:__ Cluster indicator vector x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted ratio cut (Wcut) is given by\n",
    "$$\n",
    "Wcut(A,A^c) = \\left(\\frac{1}{w(A)}+\\frac{1}{w(A^c)}\\right)cut(A,A^c)\\,,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "w(A) = \\sum_{i\\in A}w(i)\\quad\\text{and}\\quad cut(A,A^c)=\\sum_{i\\in A, j\\in A^c}w(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcut(A, w, x):\n",
    "    \"\"\" Computes weighted ratio cut value for a given flat vector x.\"\"\"\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    return (1 / (x @ w) + 1 / ((1 - x) @ w)) * (x @ A) @ (1 - x)\n",
    "\n",
    "def compute_wcut(A, w, sigma=0, t_max=100):\n",
    "    \"\"\" Compute weighted ratio cut with weighted kernel 2-means.\"\"\"\n",
    "    # Compute appropriate kernel matrix\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    \n",
    "    L = np.diag(np.sum(A, axis=1)) - A\n",
    "    K = np.diag(1 / w) * sigma + (np.diag(1 / w) @ (np.diag(w) - L)) @ np.diag(1 / w)\n",
    "    \n",
    "    # Perform weighted kernelized k-means with random initialization\n",
    "    n = A.shape[0]\n",
    "    x_old = np.random.binomial(n=1, p=.5, size=n)\n",
    "    x_old[0] = 1 - x_old[-1] # Hacky way to avoid having a vector of all 0 or all 1\n",
    "    D = np.zeros((n, 2))\n",
    "    for t in range(t_max):\n",
    "        for b in [0, 1]:\n",
    "            w_b = w * (x_old==b)\n",
    "            w_b_sum = w_b.sum()\n",
    "            D[:, b] = -2 * (K @ w_b) / w_b_sum + np.sum(w_b.reshape(-1, 1) * K * w_b) / w_b_sum ** 2\n",
    "        x_new = np.argmin(D, axis=1)        \n",
    "        if (x_old==x_new).all():\n",
    "            break\n",
    "        x_old = x_new\n",
    "    return x_new\n",
    "\n",
    "def compute_best_wcut(A, w=None, sigmas=np.linspace(-2, 2, 20)):\n",
    "    \"\"\" Compute weighted ratio cut for several sigma and take best.\"\"\"\n",
    "    x_best = []\n",
    "    best_val = np.inf\n",
    "    for sigma in sigmas:\n",
    "        x = compute_wcut(A, w, sigma=sigma)\n",
    "        if wcut(A, w, x) < best_val:\n",
    "            x_best = x\n",
    "            best_val = wcut(A, w, x)\n",
    "    return x_best\n",
    "\n",
    "def partition(V, A, n):\n",
    "    \"\"\" Compute coarse partition and translate to partition of original graph.\"\"\"\n",
    "    x_coarse = compute_spectral_wcut(A=A, w=np.array([len(v) for v in V]))\n",
    "    x = np.zeros(n)\n",
    "    for i,v in enumerate(V):\n",
    "        x[list(v)]= x_coarse[i]\n",
    "    return x\n",
    "\n",
    "def evaluate_partition_quality(x, sizes):\n",
    "    \"\"\" Evaluate the fractions that are separated by a partition in an SBM.\"\"\"\n",
    "    fractions = []\n",
    "    pos = 0\n",
    "    for i in range(len(sizes)):\n",
    "        fractions.append(x[pos: pos + sizes[i]].mean())\n",
    "        pos += sizes[i]\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Stochastical Block model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.array([500, 500])\n",
    "G = nx.stochastic_block_model(sizes=sizes, p=[[.8, .1],\n",
    "                                                 [.1, .8]])\n",
    "A = nx.to_numpy_array(G)\n",
    "V = [{i} for i in range(A.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867 [0.028, 0.99] 125.2005649830545\n",
      "737 [0.046, 0.98] 143.71315008946047\n",
      "631 [0.064, 0.956] 170.4001600640256\n",
      "523 [0.92, 0.07] 196.49564956495647\n",
      "435 [0.066, 0.866] 224.3493915866969\n",
      "368 [0.892, 0.164] 263.3980161787365\n",
      "320 [0.848, 0.166] 285.89203483882835\n",
      "271 [0.17, 0.814] 303.7137507201844\n",
      "223 [0.924, 0.392] 340.09225190636164\n",
      "189 [0.086, 0.594] 349.3360071301248\n",
      "162 [0.094, 0.554] 365.1563298999196\n",
      "134 [0.082, 0.446] 390.03314393939394\n",
      "116 [0.058, 0.372] 397.9914086801955\n",
      "106 [0.948, 0.696] 411.2263867246234\n",
      "97 [0.966, 0.786] 423.57121814700247\n",
      "87 [0.998, 0.848] 422.43671821136616\n",
      "75 [0.004, 0.152] 423.45236108793586\n",
      "67 [0.992, 0.854] 427.1784553474695\n",
      "58 [0.998, 0.902] 432.77894736842103\n",
      "48 [0.0, 0.074] 434.9021919115377\n",
      "41 [0.004, 0.066] 438.7860843819393\n",
      "34 [0.998, 0.992] 438.99497487437185\n",
      "29 [0.008, 0.024] 446.39227642276427\n",
      "21 [0.022, 0.004] 449.1465980827684\n",
      "14 [0.988, 0.996] 443.67439516129036\n",
      "13 [0.994, 0.998] 436.49598393574297\n",
      "11 [0.994, 0.998] 436.49598393574297\n",
      "9 [0.994, 0.998] 436.49598393574297\n",
      "7 [0.004, 0.002] 433.2998996990973\n",
      "5 [0.996, 0.998] 433.29989969909724\n"
     ]
    }
   ],
   "source": [
    "findCuts = FindCuts(A=A, sample_fn=sample_edges, partition_fn=partition, \n",
    "                    quality_fn=lambda x: evaluate_partition_quality(x, sizes=sizes))\n",
    "findCuts.get_cuts(T=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.666666666666664"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcut(A=A, w=None, x=compute_best_wcut(A, sigmas=np.linspace(-10,10,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yu and Shi Postprocessing: spectral approach to Wcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_wcut(A, w=None, K=2, max_iter=50):\n",
    "    \"\"\" Solves weighted ratio cut as a relaxed trace maximization problem with Yu and Shi postprocessing.\"\"\"\n",
    "    N = A.shape[0]\n",
    "    if w is None:\n",
    "        w = np.ones(N)\n",
    "    L = np.diag(np.sum(A, axis=1)) - A\n",
    "    \n",
    "    # Solve eigenvalue problem\n",
    "    w_inv_sqrt = w**(-1/2)\n",
    "    s, V = eigsh(np.eye(L.shape[0]) - w_inv_sqrt.reshape(-1, 1) * L * w_inv_sqrt,\n",
    "                 k=K, which='LA')\n",
    "    s, V = s[::-1], V[:,::-1]\n",
    "    Z = w_inv_sqrt.reshape(-1, 1) * V\n",
    "    assert np.isclose((np.diag(1/w) @ (np.diag(w)-L)) @ Z, Z @ np.diag(s)).all(), 'Eigendecomposition failed'\n",
    "    \n",
    "    # Normalize solution\n",
    "    X_tilde = 1 / np.linalg.norm(Z, axis=1, keepdims=True) * Z\n",
    "    assert np.isclose(np.linalg.norm(X_tilde, axis=1), np.ones(X_tilde.shape[0])).all(), 'Normalization failed'\n",
    "    \n",
    "    # Initialize R\n",
    "    R = np.zeros((K, K))\n",
    "    R[:, 0] = X_tilde[random.randrange(N), :]\n",
    "    c = np.zeros(N)\n",
    "    for k in range(1, K):\n",
    "        c += np.abs(X_tilde @ R[:, k-1])\n",
    "        R[:, k] = X_tilde[np.argmin(c), :]\n",
    "    \n",
    "    # Update X and R iteratively until convergence\n",
    "    psi_old = 0\n",
    "    for _ in range(max_iter):\n",
    "        # Update X\n",
    "        arg_maxs = np.argmax(X_tilde @ R, axis=1)\n",
    "        X = np.zeros_like(X_tilde)\n",
    "        X[np.arange(N), arg_maxs] = 1\n",
    "        \n",
    "        # Update R\n",
    "        U, omega, U_tilde = np.linalg.svd(X.T @ X_tilde)\n",
    "        assert np.isclose((U * omega) @ U_tilde, X.T @ X_tilde).all(), 'SVD failed'\n",
    "        psi_new = omega.sum()\n",
    "#         print(np.abs(psi_old-psi_new))\n",
    "        # Check for convergence\n",
    "        if np.isclose(psi_new, psi_old):\n",
    "#             print(f'Converged after {_} steps')\n",
    "            break\n",
    "        else:\n",
    "            psi_old = psi_new\n",
    "        R = (U @ U_tilde).T\n",
    "    return X[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.array([50, 50])\n",
    "G = nx.stochastic_block_model(sizes=sizes, p=[[.8, .1],\n",
    "                                                 [.1, .8]])\n",
    "A = nx.to_numpy_array(G)\n",
    "V = [{i} for i in range(A.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.8011083854664\n",
      "0.0\n",
      "Converged after 1 steps\n"
     ]
    }
   ],
   "source": [
    "X = compute_spectral_wcut(A)\n",
    "x = X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: comparison of different cut's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral cut: 10.440000000000001\n",
      "Block cut: 10.440000000000001\n",
      "Random cut: 45.893719806763286\n"
     ]
    }
   ],
   "source": [
    "spectral_cut = wcut(A=A, w=None, x=x) \n",
    "x_blocks = np.zeros(A.shape[0])\n",
    "x_blocks[:sizes[0]] = 1\n",
    "block_cut = wcut(A, np.ones(A.shape[0]), x_blocks)\n",
    "\n",
    "P = np.random.binomial(n=1, p=.5, size=A.shape[0])\n",
    "random_cut = wcut(A, None, P)\n",
    "print(f'Spectral cut: {spectral_cut}')\n",
    "print(f'Block cut: {block_cut}')\n",
    "print(f'Random cut: {random_cut}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
