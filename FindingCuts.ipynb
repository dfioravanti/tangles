{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph $(V, E)$ with nodes $v\\subset\\mathbb{N}$ as subsets of integers\n",
    "Strategy for merging:\n",
    "1. Draw a set of edges $F\\subseteq E$ somehow\n",
    "2. Identify connected components $\\mathcal{C}=\\{C_1,\\dotsc, C_k\\}$ of $(V, F)$. They form the new set of nodes\n",
    "3. Compute new adjacency matrix $A^\\prime$ by summing entries of $A$ blockwise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule of thumb for choosing temperature $\\tau$:\n",
    "If there are $m$ edges in an unweighted graph, the amount of chosen edges is distrubted as Bin($e$, $n^{-\\tau}$). Therefore, the expected number of chosen edges is $n^{1-\\tau}$, and a choice of \n",
    "$$\n",
    "\\tau=\\frac{\\log(2)}{\\log(m)}\n",
    "$$\n",
    "leads to $m/2$ in expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindCuts(object):\n",
    "    def __init__(self, A, sample_fn, partition_fn, quality_fn):\n",
    "        self.A = A\n",
    "        self.V = [{i} for i in range(nx.number_of_nodes(G))]\n",
    "        self.sample_fn = sample_fn\n",
    "        self.partition_fn = partition_fn\n",
    "        self.quality_fn = quality_fn\n",
    "    \n",
    "    def _merge_nodes(self, V, component):\n",
    "        \"\"\" Merge the sets of V that are indexed in component.\"\"\"\n",
    "        merged_node = set({})\n",
    "        for idx in component:\n",
    "            merged_node = merged_node.union(V[idx])\n",
    "        return merged_node\n",
    "    \n",
    "    def _merge_edges(self, V, A, A_sampled):\n",
    "        \"\"\" Merge edges in A_sampled to obtain a new graph.\"\"\"\n",
    "        G_sampled = nx.from_numpy_array(A_sampled)\n",
    "        connected_components = list(nx.connected_components(G_sampled))\n",
    "        V_coarse = [self._merge_nodes(V, component) for component in connected_components]\n",
    "        n_coarse = len(V_coarse)\n",
    "        A_coarse = np.zeros((n_coarse, n_coarse))\n",
    "        for i in range(n_coarse):\n",
    "            for j in range(i+1, n_coarse):\n",
    "                for v in connected_components[i]:\n",
    "                    for w in connected_components[j]:\n",
    "                        A_coarse[i, j] += A[v, w] \n",
    "        A_coarse += A_coarse.T\n",
    "        return V_coarse, A_coarse\n",
    "        \n",
    "    def get_cuts(self, T):\n",
    "        \"\"\" T: number of partitions\"\"\"\n",
    "        V = self.V\n",
    "        A = self.A\n",
    "        for t in range(T):\n",
    "            A_sampled = self.sample_fn(A)\n",
    "            V, A = self._merge_edges(V, A, A_sampled)\n",
    "            if len(V)==1:\n",
    "                return\n",
    "            P = self.partition_fn(V, A, n=self.A.shape[0])\n",
    "            print(self.quality_fn(P), wcut(self.A, np.ones(self.A.shape[0]), P))\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted ratio cut with weighted kernelized k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input:__ Adjacency matrix $A$ with weighted edges, $w$ vector of node weights. <br>\n",
    "__Output:__ Cluster indicator vector x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted ratio cut (Wcut) is given by\n",
    "$$\n",
    "Wcut(A,A^c) = \\left(\\frac{1}{w(A)}+\\frac{1}{w(A^c)}\\right)cut(A,A^c)\\,,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "w(A) = \\sum_{i\\in A}w(i)\\quad\\text{and}\\quad cut(A,A^c)=\\sum_{i\\in A, j\\in A^c}w(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_edges(A, temperature=.7):\n",
    "    \"\"\" Sample each edge with a probability, scaled by the temperature.\n",
    "    Returns new edges in form of adjacency matrix\"\"\"\n",
    "    edges_idx = np.triu_indices_from(A, k=1)\n",
    "    edge_probs = (A[edges_idx] / A[edges_idx].sum())**temperature\n",
    "    sampled_edges = np.random.binomial(n=1, p=edge_probs)\n",
    "    is_sampled = (sampled_edges == 1)\n",
    "    sampled_edges_idx = (edges_idx[0][is_sampled], edges_idx[1][is_sampled])\n",
    "    A_sampled = np.zeros_like(A)\n",
    "    A_sampled[sampled_edges_idx] = 1\n",
    "    A_sampled += A_sampled.T\n",
    "    return A_sampled\n",
    "\n",
    "def wcut(A, w, x):\n",
    "    \"\"\" Computes weighted ratio cut value for a given flat vector x.\"\"\"\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    return (1 / (x @ w) + 1 / ((1 - x) @ w)) * (x @ A) @ (1 - x)\n",
    "\n",
    "def compute_wcut(A, w, sigma=0, t_max=100):\n",
    "    \"\"\" Compute weighted ratio cut with weighted kernel 2-means.\"\"\"\n",
    "    # Compute appropriate kernel matrix\n",
    "    if w is None:\n",
    "        w = np.ones(A.shape[0])\n",
    "    \n",
    "    L = np.diag(np.sum(A, axis=1)) - A\n",
    "    K = np.diag(1 / w) * sigma + (np.diag(1 / w) @ (np.diag(w) - L)) @ np.diag(1 / w)\n",
    "    \n",
    "    # Perform weighted kernelized k-means with random initialization\n",
    "    n = A.shape[0]\n",
    "    x_old = np.random.binomial(n=1, p=.5, size=n)\n",
    "    x_old[0] = 1 - x_old[-1] # Hacky way to avoid having a vector of all 0 or all 1\n",
    "    D = np.zeros((n, 2))\n",
    "    for t in range(t_max):\n",
    "        for b in [0, 1]:\n",
    "            w_b = w * (x_old==b)\n",
    "            w_b_sum = w_b.sum()\n",
    "            D[:, b] = -2 * (K @ w_b) / w_b_sum + np.sum(w_b.reshape(-1, 1) * K * w_b) / w_b_sum ** 2\n",
    "        x_new = np.argmin(D, axis=1)        \n",
    "        if (x_old==x_new).all():\n",
    "            break\n",
    "        x_old = x_new\n",
    "    return x_new\n",
    "\n",
    "def compute_best_wcut(A, w=None, sigmas=np.linspace(-2, 2, 20)):\n",
    "    \"\"\" Compute weighted ratio cut for several sigma and take best.\"\"\"\n",
    "    x_best = []\n",
    "    best_val = np.inf\n",
    "    for sigma in sigmas:\n",
    "        x = compute_wcut(A, w, sigma=sigma)\n",
    "        if wcut(A, w, x) < best_val:\n",
    "            x_best = x\n",
    "            best_val = wcut(A, w, x)\n",
    "    return x_best\n",
    "\n",
    "def partition(V, A, n):\n",
    "    \"\"\" Compute coarse partition and translate to partition of original graph.\"\"\"\n",
    "    x_coarse = compute_best_wcut(A=A, w=np.array([len(v) for v in V]))\n",
    "    x = np.zeros(n)\n",
    "    for i,v in enumerate(V):\n",
    "        x[list(v)]= x_coarse[i]\n",
    "    return x\n",
    "\n",
    "def evaluate_partition_quality(x, sizes):\n",
    "    \"\"\" Evaluate the fractions that are separated by a partition in an SBM.\"\"\"\n",
    "    fractions = []\n",
    "    pos = 0\n",
    "    for i in range(len(sizes)):\n",
    "        fractions.append(x[pos: pos + sizes[i]].mean())\n",
    "        pos += sizes[i]\n",
    "    return fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Stochastical Block model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.array([50, 50])\n",
    "G = nx.stochastic_block_model(sizes=sizes, p=[[.8, .1],\n",
    "                                                 [.1, .8]])\n",
    "A = nx.to_numpy_array(G)\n",
    "V = [{i} for i in range(A.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52, 0.42]\n",
      "[0.48, 0.52]\n",
      "[0.52, 0.54]\n",
      "[0.42, 0.44]\n",
      "[0.6, 0.38]\n",
      "[0.56, 0.46]\n",
      "[0.52, 0.44]\n",
      "[0.42, 0.6]\n",
      "[0.62, 0.34]\n",
      "[0.62, 0.62]\n",
      "44.87064380414843\n"
     ]
    }
   ],
   "source": [
    "rnd_cuts = []\n",
    "for _ in range(10):\n",
    "    P = np.random.binomial(n=1, p=.5, size=A.shape[0])\n",
    "    print(evaluate_partition_quality(P, sizes=sizes))\n",
    "    rnd_cuts.append(wcut(A, None, P))\n",
    "mean = np.array(rnd_cuts).mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_blocks = np.zeros(A.shape[0])\n",
    "x_blocks[:sizes[0]] = 1\n",
    "wcut(A, np.ones(A.shape[0]), x_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58, 0.38] 43.18910256410256\n",
      "[0.26, 0.6] 40.881272949816406\n",
      "[0.36, 0.64] 42.6\n",
      "[0.82, 0.42] 39.21901528013582\n",
      "[0.2, 0.64] 37.315270935960584\n",
      "[0.88, 0.4] 36.197916666666664\n",
      "[0.12, 0.58] 36.21978021978022\n",
      "[0.88, 0.36] 34.507640067911716\n",
      "[0.94, 0.54] 37.16216216216216\n",
      "[0.08, 0.64] 32.248263888888886\n",
      "[0.94, 0.36] 31.64835164835165\n",
      "[0.06, 0.58] 33.455882352941174\n",
      "[0.0, 0.12] 40.78014184397163\n",
      "[0.98, 0.84] 40.17094017094016\n",
      "[0.02, 0.04] 41.5807560137457\n",
      "[0.96, 0.98] 40.20618556701031\n",
      "[0.96, 0.98] 39.86254295532646\n",
      "[0.98, 0.98] 42.85714285714286\n",
      "[0.98, 1.0] 36.36363636363637\n"
     ]
    }
   ],
   "source": [
    "findCuts = FindCuts(A=A, sample_fn=sample_edges, partition_fn=partition, \n",
    "                    quality_fn=lambda x: evaluate_partition_quality(x, sizes=sizes))\n",
    "findCuts.get_cuts(T=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.666666666666664"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcut(A=A, w=None, x=compute_best_wcut(A, sigmas=np.linspace(-10,10,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yu and Shi Postprocessing: spectral approach to Wcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_wcut(A, w=None, K=2, max_iter=50):\n",
    "    \"\"\" Solves weighted ratio cut as a relaxed trace maximization problem with Yu and Shi postprocessing.\"\"\"\n",
    "    N = A.shape[0]\n",
    "    if w is None:\n",
    "        w = np.ones(N)\n",
    "    L = np.diag(np.sum(A, axis=1)) - A\n",
    "    \n",
    "    # Solve eigenvalue problem\n",
    "    w_inv_sqrt = w**(-1/2)\n",
    "    s, V = eigsh(np.eye(L.shape[0]) - w_inv_sqrt.reshape(-1, 1) * L * w_inv_sqrt,\n",
    "                 k=K, which='LA')\n",
    "    s, V = s[::-1], V[:,::-1]\n",
    "    Z = w_inv_sqrt.reshape(-1, 1) * V\n",
    "    assert np.isclose((np.diag(1/w) @ (np.diag(w)-L)) @ Z, Z @ np.diag(s)).all(), 'Eigendecomposition failed'\n",
    "    \n",
    "    # Normalize solution\n",
    "    X_tilde = 1 / np.linalg.norm(Z, axis=1, keepdims=True) * Z\n",
    "    assert np.isclose(np.linalg.norm(X_tilde, axis=1), np.ones(X_tilde.shape[0])).all(), 'Normalization failed'\n",
    "    \n",
    "    # Initialize R\n",
    "    R = np.zeros((K, K))\n",
    "    R[:, 0] = X_tilde[random.randrange(N), :]\n",
    "    c = np.zeros(N)\n",
    "    for k in range(1, K):\n",
    "        c += np.abs(X_tilde @ R[:, k-1])\n",
    "        R[:, k] = X_tilde[np.argmin(c), :]\n",
    "    \n",
    "    # Update X and R iteratively until convergence\n",
    "    psi_old = 0\n",
    "    for _ in range(max_iter):\n",
    "        # Update X\n",
    "        arg_maxs = np.argmax(X_tilde @ R, axis=1)\n",
    "        X = np.zeros_like(X_tilde)\n",
    "        X[np.arange(N), arg_maxs] = 1\n",
    "        \n",
    "        # Update R\n",
    "        U, omega, U_tilde = np.linalg.svd(X.T @ X_tilde)\n",
    "        assert np.isclose((U * omega) @ U_tilde, X.T @ X_tilde).all(), 'SVD failed'\n",
    "        psi_new = omega.sum()\n",
    "        print(np.abs(psi_old-psi_new))\n",
    "        # Check for convergence\n",
    "        if np.isclose(psi_new, psi_old):\n",
    "            print(f'Converged after {_} steps')\n",
    "            break\n",
    "        else:\n",
    "            psi_old = psi_new\n",
    "        R = (U @ U_tilde).T\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.array([50, 50])\n",
    "G = nx.stochastic_block_model(sizes=sizes, p=[[.8, .1],\n",
    "                                                 [.1, .8]])\n",
    "A = nx.to_numpy_array(G)\n",
    "V = [{i} for i in range(A.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.8011083854664\n",
      "0.0\n",
      "Converged after 1 steps\n"
     ]
    }
   ],
   "source": [
    "X = compute_spectral_wcut(A)\n",
    "x = X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: comparison of different cut's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral cut: 10.440000000000001\n",
      "Block cut: 10.440000000000001\n",
      "Random cut: 45.893719806763286\n"
     ]
    }
   ],
   "source": [
    "spectral_cut = wcut(A=A, w=None, x=x) \n",
    "x_blocks = np.zeros(A.shape[0])\n",
    "x_blocks[:sizes[0]] = 1\n",
    "block_cut = wcut(A, np.ones(A.shape[0]), x_blocks)\n",
    "\n",
    "P = np.random.binomial(n=1, p=.5, size=A.shape[0])\n",
    "random_cut = wcut(A, None, P)\n",
    "print(f'Spectral cut: {spectral_cut}')\n",
    "print(f'Block cut: {block_cut}')\n",
    "print(f'Random cut: {random_cut}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
